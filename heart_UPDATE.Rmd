---
title: "Heart Disease Prediction"
author: "A. Nguyen, B. Waite"
date: "7/17/2019"
output:
  html_document: default
  pdf_document: default
---


#Introduction: 

This study hopes to identify factors contributing to the development of heart disease in an observed population and to train a logistic regression model to predict whether future patients will develop heart disease given the same set of factors. 

#Data: 

The data used in this study were obtained from the archives of the University of California, Irvine and are available on the web at: https://archive.ics.uci.edu/ml/datasets/Heart+Disease. 

A brief summary of the variables contained in the data is available in the table below. A more robust description of each variable is contained in Appendix A. 

```{r include = FALSE, message = FALSE}
library(readr)
library(knitr)
library(kableExtra)
library(car)
library(gplots)
library(ggplot2)
library(GGally)
library(generalhoslem)
library(caret)
library(PredPsych)
library(pROC)
library(tree)
library(randomForest)
library(ROCR)
library(heplots)
library(MASS)

#Requires setwd() to the current directory with heart.csv
heart <- read_csv("heart.csv")

#Convert the categorical variables to factors
heart$sex = as.factor(heart$sex)
heart$cp = as.factor(heart$cp)
heart$fbs = as.factor(heart$fbs)
heart$restecg = as.factor(heart$restecg)
heart$exang = as.factor(heart$exang)
heart$slope = as.factor(heart$slope)
heart$ca = as.factor(heart$ca)
heart$thal = as.factor(heart$thal)
heart$target = as.factor(heart$target)

#Summary Statistcs
sumstats = summary(heart)

#Dataset Structure
datastructure = str(heart)
attach(heart)

#Set Reference group to be no heart disease
heart$target <- relevel(heart$target, ref = "0")

```


```{r echo = FALSE}

vartable = as.data.frame(names(heart))
vartable$description = c("Age","Sex","Chest Pain Type","Resting Blood Pressure at Admission","Serum Cholesterol","Fasting Blood Sugar > 120 mg/dl","Resting Electrocardiographic Results","Maximum Heart Rate Achieved","Exercised Induced Angina", 
                         "ST Depression Induced by exercise relative to rest", "The Slope of the Peak Exercise ST Segment","Number of Major Vessels Colored by Flouroscopy", "Severity of Defect","Diagnosis of Heart Disease")
vartable$typeOrUnits = c("Years", "1 = Male;0 = Female", "0 = Typical Angina, 1 = Atypical Angina, 2 = Non-Anginal Pain, 3 = Asymptomatic", "mmHg","mg/dl","1 = true; 0 = false","0 = Normal, 1 = Having ST-T Wave Abnormality, 2 = Showing Probable or Definite left ventricular hypertrophy","Beats Per Minute (BPM)","1 = Yes; 0 = No","Unknown","1 = Upsloping, 2 = Flat, 3 = Downsloping","0-3","3 = normal; 6 = fixed defect; 7 = reversable defect","0 = No Heart Disease Diagnosed; 1 = Heart Disease Diagnosed")
vartable$usage = "Predictor"
vartable$usage[14] = "Response"
names(vartable) = c("Variable","Description","Units or Value","Usage")
kable(vartable) %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```


Some interesting breakdowns / observations contained within the data:

* The age range in the data set is from 29 to 77 years old. Age distribution is normal. 
* There are 303 total participants.  207 Male and 96 Female.
* Nearly balanced response samples: 138 no heart disease vs 165 with heart disease.
* General contingency tables of Sex by Target (diagnosed with cardiac disease) shows:
  * Proportion of female with heart disease is greater than proportion of male with heart disease

```{r echo = FALSE}
ftable(addmargins(table(sex,target)))
prop.table(table(sex,target),2)
```

* In examining the histogram for Cholestorol values, we can see that there is at least one outlier with a value of 564 mg/dl (*observation 303: 67 year old female*). We might want to explore this further. 
* The oldpeak variable also shows some diferentiation in the outcome of having heart disease. 

```{r echo = FALSE}

#Boxplot of oldpeak
boxplot(oldpeak~target, main = "Heart Disease or Not vs Oldpeak", xlab = "Heart Disease Present", ylab = "Oldpeak Value")
```

* There also appear to be some outliers in the oldpeak data set that you can see on the boxplot above and are present in the histogram that is right skewed. Log transforming the oldpeak variable does help with normality. We don't know if this is required at this point, but is good to keep in mind and may help to improve our prediction model later. 

```{r echo = FALSE}
#Histogram of oldpeak
hist(oldpeak)
#Some strong right skew here that may need to be addressed if we use this as a continuous variable. And I think we should initially. 

#log transform of oldpeak
hist(log(oldpeak))
```

The maximum heart rate achieved during the stress test (thalach) also appears to be strongly correlated with the outcome of whether a patient will have heart disease or not. 

```{r echo = FALSE, message = FALSE} 
#Histogram of thalach
hist(thalach)

#Boxplot of thalach against response
boxplot(thalach~target, main = "Maximum Heart Rate Achieved Grouped by Heart Disease or No", xlab = "Heart Disease Present", ylab = "Heart Rate in Beats Per Minute (BPM)", col = c("blue","red"))
#Some good differentiation here
```

Visualizing the Relationships between Response and Categorical Predictors through Stacked Bargraphs

```{r Visualization of Categorical Variables, echo = FALSE}
# Sex
plot(target~sex, main = "Heart Disease by Sex", xlab = "Sex", ylab = "Heart Disease (Target)", col=c("blue","red"))

# Chest Pain
plot(target~cp, main = "Heart Disease by Chest Pain", xlab = "Chest Pain", ylab = "Heart Disease (Target)", col=c("blue","red"))

# Fasting Blood Sugar
plot(target~fbs, main = "Heart Disease by Fasting Blood Sugar", xlab = "Fasting Blood Sugar (fbs)", ylab = "Heart Disease (Target)", col=c("blue","red"))

# Resting Electrocardiogram Result
plot(target~restecg, main = "Heart Disease by Resting Electrocardiogram Result", xlab = "Resting Electrocardiogram Result (restecg)", ylab = "Heart Disease (Target)", col=c("blue","red"))

# Exercised Induced Angina
plot(target~exang, main = "Heart Disease by Exercised Induced Angina", xlab = "Exercised Induced Angina (exang)", ylab = "Heart Disease (Target)", col=c("blue","red"))

# Slope of ST Segment
plot(target~slope, main = "Heart Disease by Slope of ST Segment", xlab = "Slope of ST Segment (slope)", ylab = "Heart Disease (Target)", col=c("blue","red"))

# Fluoroscopic Colored Vessels
plot(target~ca, main = "Heart Disease by Fluoroscopic Colored Vessels", xlab = "Fluoroscopic Colored Vessels (ca)", ylab = "Heart Disease (Target)", col=c("blue","red"))

# Heart Defect Severity
plot(target~thal, main = "Heart Disease by Heart Defect Severity", xlab = "Heart Defect Severity (thal)", ylab = "Heart Disease (Target)", col=c("blue","red"))
```

* Visualizations + additional contingency tables (Appendix B) show:
  * positive correlation between chest pain (*cp*) and heart disease (*target*)
  * possible negative correlation between exercise induced angina (*exang*) and heart disease (*target*)
  * negative correlation between fluoroscopic colored vessels (*ca*) and heart disease (*target*)
  * higher proportion of patients with defect level (*thal*) of 2 have heart disease while higher proportion of patients at other defect levels do not have heart disease [REQUIRES FURTHER INVESTIGATION]

<br>

Visualizing the Relationships between Response and Continuous Predictors through Boxplots

```{r Visualization of Continuous Variables, echo = FALSE}
# Age
plot(age~target, col=c("blue","red"), main = "Heart Disease by Age", xlab = "Heart Disease", ylab = "Age")

# Resting Blood Pressure at Time of Admission
plot(trestbps~target, col=c("blue","red"), main = "Heart Disease by Resting Blood Pressure", xlab = "Heart Disease", ylab = "Resting Blood Pressure (mmHg)")

# Serum Cholesterol Level
plot(chol~target, col=c("blue","red"), main = "Heart Disease by Serum Cholestrol", xlab = "Heart Disease", ylab = "Serum Cholestrol (mg/dL)")

# Maximum Heart Rate Achieved
plot(thalach~target, col=c("blue","red"), main = "Heart Disease by Maximum Heart Rate Achieved", xlab = "Heart Disease", ylab = "Maximum Heart Rate Achieved (bpm)")

# ST Segment Depression
plot(oldpeak~target, col=c("blue","red"), main = "Heart Disease by ST Segment Depression", xlab = "Heart Disease", ylab = "ST Segment Depression (oldpeak)")
```

<br>

Visualize Correlation Patterns and Distributions of Continuous Variables
``` {r Scatterplot Matrix w/ Histogram on Diagonal, echo = FALSE}
# Scatterplot Matrix
scatterplotMatrix(x = heart[,-c(2,3,6,7,9,11,12,13)],
                  smooth = FALSE,
                  regLine = list(method=lm, lty=1, lwd=2, col="black"),
                  groups = target,
                  col = c("blue", "red"))

# Correlation Coefficients
#my.cor<-cor(heart[,-c(2,3,6,7,9,11,12,13,14)])

# Heatmap to Visualize Correlations between continuous predictors
# heatmap.2(my.cor,col=redgreen(75), 
#          density.info="none", trace="none", dendrogram=c("row"), 
#          symm=F,symkey=T,symbreaks=T, scale="none")

```


## Let's try to do some PCA: 

```{r include = FALSE}
#Get only the continuous variables
heartcont = heart[,c('age','trestbps','chol','thalach','oldpeak')]
pairs(heartcont, panel = panel.smooth)
```


Looking at these plots, there does not seem to be much correlation between the continuous variables. The heatmap below seems to confirm this. 

```{r echo = FALSE, message = FALSE}
library(gplots)
my.cor2 = cor(heartcont)
heatmap.2(my.cor2,col=redgreen(75), 
          density.info="none", trace="none", dendrogram=c("both"), 
          symm=F,symkey=T,symbreaks=T, scale="none",key=T)

cov(heartcont)
```

<br>

```{r echo = FALSE}
#Looking at Principal Components with scaling (using the correlation values vice the covariance values)
pcomps <- prcomp(heartcont, scale.= TRUE)
pcscores <- pcomps$x
pairs(pcscores, panel = panel.smooth)

# checking correlation of PCs
round(cor(pcscores),2)
```

There do not seem to be any correlations in the Principal Components. Let's try to produce the Scree / Cumulative Proportion Plots: 

```{r echo = FALSE}
par(mfrow=c(1,2))
eigenvals<-(pcomps$sdev)^2
plot(1:5,eigenvals/sum(eigenvals),type="l",main="Scree Plot",ylab="Prop. Var. Explained", ylim = c(0,.4))
cumulative.prop<-cumsum(eigenvals/sum(eigenvals))
plot(1:5,cumulative.prop,type="l",main="Cumulative proportion")# ,ylim=c(0,1))
par(mfrow=c(1,1))
```

It looks like from the above plot, that 90.53% of the variability can be explained using 4 principal components. It does appear, though that all 5 continue to contribute to the model which is consistent with our earlier assessment that there is not significant correlation among the predictors. 

```{r echo = FALSE, message = FALSE}
pcscores = data.frame(pcscores)
ggplot(data = pcscores, aes(x = PC1, y = PC2)) +
  geom_point(aes(col=target), size=1)+
  ggtitle("PCA of Heart Disease Data")

heartcont$target = as.factor(heart$target)
```

This pairs plot explores the correlation between the continuous predictors grouped by the outcome: 

```{r echo = FALSE, message = FALSE}
#pairs on variables grouped by target

ggpairs(heartcont, columns=1:5, aes(color=target)) + 
  ggtitle("Heart Disease Original Variables Grouped by Target (Diagnosis)")
```

While this pairs plot explores the correlation between the Principal Components grouped by the outcome. 

```{r echo = FALSE, message = FALSE}
#pairs on principal components grouped by target
pcscores$target = as.factor(heart$target)
ggpairs(pcscores, columns=1:5, aes(color=target)) + 
  ggtitle("Heart Disease Principal Components Grouped by Target (Diagnosis)")

```

Running a number of PCA charts coded by response does not appear to show a clean discriminant that we can use to do regression on the Principal Components. Principal component 1 (PC1) does show some ability to distinguish against PC2, but there is still significant overlap. This indicates that these 5 continuous predictors may not perform well in a classfication model. Additional continuous predictors may help improve the performance of our model. The categorical predictors might have greater influence to differentiate with interaction terms. 

Looking at the weighting on the principal components: 

```{r echo = FALSE}
pcomps$rotation
```

In looking at this table, we can see that each variable contributes a significant amount in at least one of the Principal Components. This is a good indication that the variables are not correlated with each other and that each might contribute something unique to our model.
  * PC1 seems to be a contrast between age and thalach.
  * PC2 seems to be largely influenced by chol, thalach, and trestbps.
  * PC3 seems to be a contrast between trestbps and chol.
  * PC4 seems to be a contrast between age and oldpeak.
  * PC5 seems to be largely influenced by age and thalach.
<br>
<br>

# Prep for Analysis

I considered doing a Train / Test split on the data, but think that we might try to do a k-fold cross validation of the model. In order to do that, we have to train the model first. 

```{r echo = FALSE, message = FALSE}
library(caret) 

levels(heart$target) = c("No","Yes")
#define the training control method for the model -- This is the cross validation. 
train_control = trainControl(method = "cv", number = 10, classProbs = TRUE, savePredictions = TRUE, summaryFunction = twoClassSummary)

#fit the simple model using all the variables
simple_model = train(target~., data = heart, trControl = train_control, method = "glm", metric = "ROC", family = "binomial")

#plot the ROC curve
testroc = roc(predictor = simple_model$pred$Yes, response = simple_model$pred$obs, levels = rev(levels(simple_model$pred$obs)))

plot(testroc, type = "S")
text(x = .40, y = .6,paste("AUC = ", round(testroc$auc, 3)))
```

and the coefficients: 

```{r echo = FALSE, message = FALSE}
simple_model$finalModel
```

Run the Hosmer / Lemeshow GOF test on the simple model: 

```{r}
library(generalhoslem)
logitgof(heart$target, fitted(simple_model))
```

Get the odds ratio and confidence intervals for the simple model

```{r}
#odds ratio and confidence interval for the odds ratio
exp(cbind("Odds ratio" = coef(simple_model$finalModel), confint.default(simple_model$finalModel, level = 0.95)))

#Variance Inflation Factor (VIF)
vif(simple_model$finalModel)
```
<br>
<br>

# Stepwise Feature Selection (AIC-based): 

```{r Stepwise Feature Selection of Simple Logistic Regression Model, echo = FALSE, message = FALSE}
levels(heart$target) = c("No","Yes")
#define the training control method for the model -- This is the cross validation. 
train_control = trainControl(method = "cv", number = 10, classProbs = TRUE, savePredictions = TRUE, summaryFunction = twoClassSummary)

#This line makes a lot of output when knitted
simple_model_stepwise = train(target~., data = heart, trControl = train_control, method = "glmStepAIC", family = "binomial", metric = "ROC")

simple_model_stepwise$finalModel$coefficients

simple_model_stepwise$results

# Hosmer-Lemeshow Goodness of Fit Test
logitgof(heart$target, fitted(simple_model_stepwise))

# Model Assumptions and Diagnostics
par(mfrow = c(2,2))
plot(simple_model_stepwise$finalModel)

# Odds Ratio and Confidence Intervals
exp(cbind("Odds ratio" = coef(simple_model_stepwise$finalModel), confint.default(simple_model_stepwise$finalModel, level = 0.95)))

#Variance Inflation Factor (VIF)
vif(simple_model_stepwise$finalModel)

# Plot the ROC-AUC curve
par(mfrow = c(1,1))
testroc <- roc(predictor = simple_model_stepwise$pred$Yes, response = simple_model_stepwise$pred$obs, levels = rev(levels(simple_model_stepwise$pred$obs)),
              smoothed=FALSE, ci=FALSE, plot=TRUE, print.auc=TRUE)
```
<br>
<br>

# Decision Tree on Simple Stepwise Model:

``` {r Decision Tree}

# Training (66%) /Test (33%) Split
set.seed(777)
heart.train <- sample(1:nrow(heart), 202)
heart.test <- heart[-heart.train,]
# Independent response to compare prediction performance on test set
response.test <- target[-heart.train]

# Decision Tree based off Stepwise Feature Selection of Logistic Regression Model
heart.tree <- tree(target ~ thal + ca + cp + sex + trestbps + exang + oldpeak + slope, data = heart, subset = heart.train)
summary(heart.tree)
plot(heart.tree)
text(heart.tree)

# Cross-validate to determine optimal Pruned Tree
cv.heart <- cv.tree(heart.tree,FUN=prune.misclass)
cv.heart

# Smallest Misclassifcation Rate from size 8-13
plot(cv.heart)

# Prune Tree to Optimized Number of Nodes (8)
prune.heart <- prune.tree(heart.tree, best=8)
plot(prune.heart)
text(prune.heart,pretty=0)

# Predict on Test Set
heart.tree_pred <- predict(prune.heart, heart.test, type="class")
table(heart.tree_pred, response.test)

# Performance Metrics
TN <- 38
TP <- 39
FN <- 12
FP <- 12
Total <- TN + TP + FN + FP
## Accuracy
acc <- (TP+TN)/Total
acc
## Sensitivity
sen <- TP/(TP+FN)
sen
## Specificity
spe <- TN/(TN+FP)
spe

# ROC Curve for Single Tree
tree.pred <- predict(prune.heart,heart.test,type="vector")

pred <- prediction(tree.pred[,2], heart.test$target)
roc.perf <-  performance(pred, measure = "tpr", x.measure = "fpr")
auc <- performance(pred, measure = "auc")
auc <- auc@y.values
plot(roc.perf, main= "AUC of Test Set for a Single Tree")
abline(a=0, b= 1)
text(x = .40, y = .6, paste("AUC = ", round(auc[[1]],3), sep = ""))
```

The decision tree shows that thal, cp, and ca may be most important predictors for heart disease. Consider interaction terms for these variables in more complex model. From the optimized prune tree, oldpeak and sex also seems to influence classification of heart disease.
<br>

# Random Forests on Simple Stepwise Model:

``` {r Random Forest}
# Random Forest based off Stepwise Feature Selection of Logistic Regression Model
## 4 predictors chosen to be sampled for each bootstrap sample (mtry = 4)
RF.heart <- randomForest(target ~ thal + ca + cp + sex + trestbps + exang + oldpeak + slope, data = heart, subset = heart.train,
                         mtry = 4, importance = TRUE, ntree = 100)

# Predict on Test Set
RF.pred <- predict(RF.heart, newdata=heart.test, type="response")
table(RF.pred,heart.test$target)

# Performance Metrics
TN <- 43
TP <- 39
FN <- 7
FP <- 12
Total <- TN + TP + FN + FP
## Accuracy
acc <- (TP+TN)/Total
acc
## Sensitivity
sen <- TP/(TP+FN)
sen
## Specificity
spe <- TN/(TN+FP)
spe

# ROC Curve for Random Forest
RF.pred <- predict(RF.heart, newdata=heart.test, type="prob")
pred <- prediction(RF.pred[,2], heart.test$target)
roc.perf <- performance(pred, measure = "tpr", x.measure = "fpr")
auc <- performance(pred, measure = "auc")
auc <- auc@y.values
plot(roc.perf, main="AUC of Test set for Random Forest (4 predictors per bootstrap)")
abline(a=0, b= 1)
text(x = .40, y = .6,paste("AUC = ", round(auc[[1]],3), sep = ""))
```

Random Forest provided better perfomance metrics than Decision Tree using 4 predictors per bootsrap sample. AUC = 0.891 in Random Forest compared to AUC = 0.838 from Decision Tree.

``` {r Variable Importance}
# MeanDecreaseAccuracy impurity metric: amount RSS is decreased due to splits over a given predictor (primarily used for bagged regression trees)
varImpPlot (RF.heart,type=1,main="Variable Importance")

# MeanDecreaseGini impurity metric: amount Gini index is decreased by splits over a given predictor (primarily used for bagged classification trees)
varImpPlot (RF.heart,type=2,main="Variable Importance")
```
<br>
<br>

# More complex model

```{r echo = FALSE, message = FALSE}


#define the training control method for the model -- This is the cross validation. 
train_control = trainControl(method = "cv", number = 10)

#fit the complex model using all the variables and some guessed interaction terms
#gives accuracy improvement
complex_model = train(target~age + sex + cp + trestbps + chol + fbs + restecg + thalach + exang + log(oldpeak+.01) + slope + ca + thal + oldpeak*trestbps + oldpeak*age , data = heart, trControl = train_control, method = "glm", family = "binomial")

#fit the complex model using all the variables and elasticnet selection. Does better than simple, but hit or miss as to whether better than our guessed fit. 
complex_model_elasticnet = train(target~age + sex + cp + trestbps + chol + fbs + restecg + thalach + exang + log(oldpeak+0.001) + slope + ca + thal + oldpeak*trestbps + oldpeak*age, data = heart, trControl = train_control, method = "glmnet", family = "binomial")
```


# LDA

Let's run an LDA model on the continuous variables and see how the model performs: 

```{r Discriminant Analysis}
# Assumptions are Multivariate Normally Distributed Residual and Equal Covariance Matricies
## Histogram of logged oldpeak predictor improves normality

#Run the LDA
heart_lda = LinearDA(Data = as.data.frame(heartcont), selectedCols = c("age","trestbps", "chol", "thalach", "oldpeak", "target"), classCol = 6, cvType = "folds", nTrainFolds = 10, extendedResults = TRUE)

#output the results
heart_lda$ConfusionMatrixResults


# Box's M-Test for homogeneity of covariance matricies (test requires multivariate normal data)
## Did not work for simply logging oldpeak, since any obserations with 0 resulted in undefined value from the transformation (no p-value provided)
# res <- boxM(cbind(age,trestbps,chol,thalach,log(oldpeak)) ~ target, data = heart)

# Alternative check to covariance assumption through visualization of Covariance Ellipses
covEllipses(heart[,c("age","trestbps","chol","thalach","oldpeak")], heart$target, 
            fill=c(rep(FALSE,3), TRUE), variables=1:5, fill.alpha=.1)

# Build QDA model due to violation of homogeneous covariance matricies
heart.qda <- qda(target ~ age + trestbps + chol + thalach + oldpeak, CV = TRUE, data = heart)
table(heart$target, heart.qda$class, dnn = c('Actual Group','Predicted Group'))

# Performance Metrics
TN <- 85
TP <- 136
FN <- 29
FP <- 53
Total <- TN + TP + FN + FP
## Accuracy
acc <- (TP+TN)/Total
acc
## Sensitivity
sen <- TP/(TP+FN)
sen
## Specificity
spe <- TN/(TN+FP)
spe
```
The LDA/QDA models will not perform as well logistic regression model. QDA should be used in favor of LDA model since assumptions of equal covariance matrix is violated as shown in the Covariance Ellipses Matrix. However, the assumption of multivariate normally distributed data is also violated with oldpeak predictor, so logistic regression model should be used in favor of QDA for classification of heart disease.

<br>
<br>
 

Just to try another selection algorithm, used "LogitBoost" from the Caret library. It doesn't consistently outperform the simpler stepwise selection or "all-in" methods. We haven't learned the interpretation for this model.  

```{r echo = FALSE, message = FALSE}
simple_model_boost = train(target~., data = heart, trControl = train_control, method = "LogitBoost", family = "binomial")

simple_model_boost$finalModel

simple_model_boost$results
```

Elasticnet: 

```{r echo = FALSE, message = FALSE}

#define the training control method for the model -- This is the cross validation. 
train_control = trainControl(method = "cv", number = 10)

#fit the simple model using all the variables
simple_model_elastic = train(target~., data = heart, trControl = train_control, method = "glmnet", family = "binomial")

#odds ratio and confidence interval for the odds ratio
odds_ratio_elastic = exp(coef(simple_model_elastic$finalModel, simple_model_elastic$bestTune$lambda))
odds_ratio_elastic

```


# Appendix A: 


Variable names and meanings pulled from the source website: https://archive.ics.uci.edu/ml/datasets/Heart+Disease


*Chest Pain Type (cp)* [SOURCE: https://www.aafp.org/afp/2005/1115/p2012.html]
  
Angina is chest pain that results from reduced blood flow to the heart muscle.

Typical angina (definite chest pain) meets three of the following characteristics

1. Substernal chest discomfort of characteristic quality and duration
2. Provoked by exertion or emotional stress
3. Relieved by rest and/or nitroglycerine

Atypical angina (probable chest pain) meets two of the characteristics

Non-anginal pain meets one characteristic

Asymptomatic means no chest pain
    

*Resting Blood Pressure (trestbps)*

High blood pressure is a common condition and major risk factor for heart disease. Uncontrolled hypertension can lead to heart attack and stroke
    
*Serum Cholesterol (chol)* 

[SOURCE: https://www.medicalnewstoday.com/articles/321519.php]

Serum cholesterol measures the amount of triglycerides, low-density lipoprotein (LDL/bad cholesterol), and high density lipoprotein (HDL/good cholesterol). High serum cholesterol levels are associated with higher risk for coronary artery disease and heart attack

*Normal Ranges for cholesterol levels*

<= 19 years old - serum chol [<= 170 mg/dL] - HDL [>= 45 mg/dL] - LDL [< 100 mg/dL] - Triglycerides [< 150 mg/dL]
>= 20 years old female - serum chol [125-200 mg/dL] - HDL [>= 50 mg/dL] - LDL [< 100 mg/dL] - Triglycerides [< 150 mg/dL]
>= 20 years old male - serum chol [125-200 mg/dL] - HDL [>= 40 mg/dL] - LDL [< 100 mg/dL] - Triglycerides [< 150 mg/dL]

*Fasing Blood Sugar (fbs)* 

[SOURCE: https://www.mayoclinic.org/diseases-conditions/diabetes/diagnosis-treatment/drc-20371451]

Ranges:

1. fbs < 100 mg/dL is normal
2. fbs 100-125 mg/dL is prediabetes
3. fbs >= 126 mg/dL on two separate tests diagnoses diabetes

A fasting blood sugar level of more than 125 mg/dL is current threshold for diabetes. Higher fasting blood sugars are associatied with higher risk for heart disease. 
    
*Resting Electrocardiographic Results (restecg)* 

[SOURCE: https://www.mayoclinic.org/diseases-conditions/left-ventricular-hypertrophy/symptoms-causes/syc-20374314]

ST-T Wave Abnormality (1) are associated with increased cardiac deaths and are highly suggestive of coronary artery disease when associcated with cardiac signs and symptoms. T wave inversions and/or ST elevation or depression of > 0.05 mV. 

Left Ventricular Hypertrophy (2) is enlargement/thickening (hypertrophy) of the walls of your heart's main pumping chamber (left ventricle) and causes it to work harder. 

  * Defined using Estes' criteria
  * As the workload increases, the muscle tissue in the chamber wall thickens. The enlarged heart muscle loses elasticity and may eventually fail to pump with as much force as needed.
  * Left ventricular hypertrophy is more common in people who have uncontrolled high blood pressure and puts you at higher risk of a heart attack and stroke.
      
  
*Maximum Heart Rate Achieved (thalach)* 

[SOURCE: https://www.hopkinsmedicine.org/health/wellness-and-prevention/understanding-your-target-heart-rate]

The maximum heart rate is based on your age, as subtracted from 220. 

  * For a 50-year-old, maximum heart rate is 220 minus 50, or 170 beats per minute. 
  * Target heart rate that a 50-year-old would want to aim for during exercise is 85 to 145 beats per minute (50%-85% exertion level).
  * Maximum heart rates below these averages may indicate weakening of heart muscle
    
*Exercise Induced Angina*

Chest pain that is triggered by physical exertion. When you climb stairs, exercise or walk, your heart demands more blood, but it's harder for the muscle to get enough blood when your arteries are narrowed.
    
*ST Depression Induced (oldpeak)*

[SOURCE: https://www.ahajournals.org/doi/pdf/10.1161/01.CIR.80.1.87]

* Units are in mm or mV?

 ST segment depression in PQRST wave (ECG) may be assoicated with coronary artery disease with larger depressions indicative of abnormality. Exercise stress test requires an ST depression of at least 2 mm to significantly indicate reversible ischaemia [WIKI]
  
*Slope of Peak Exercise ST Segment (slope)*

[SOURCE: https://ecgwaves.com/ecg-topic/exercise-stress-test-ecg-symptoms-blood-pressure-heart-rate-performance/]

* Steep slopes indicate a less likely chance of ischemia
* Horizontal/Flat slopes indicate a more likely chance of ischemia
  
*Number of Major Vessels Colored by Flouroscopy (ca)*

*Severity of Defect (thal)*

*target*

Diagnosis of heart disease (angiographic disease status)

Value 0: < 50% diameter narrowing
Value 1: > 50% diameter narrowing (in any major vessel: attributes 59 through 68 are vessels)

# Appendix B: Additional Exploratory Analysis Performed

```{r include = FALSE}
# General Contingency/Proportions Tables of Categorical Predictors on Response

## Chest Pain & Heart Disease
ftable(addmargins(table(cp,target)))
prop.table(table(cp,target),2)

## Fasting Blood Sugar & Heart Disease
ftable(addmargins(table(fbs,target)))
prop.table(table(fbs,target),2)

## Resting ECG results & Heart Disease
ftable(addmargins(table(restecg,target)))
prop.table(table(restecg,target),2)

## Exercise Induced Angina & Heart Disease
ftable(addmargins(table(exang,target)))
prop.table(table(exang,target),2)

## Slope of ST Segment & Heart Disease
ftable(addmargins(table(sex,target)))
prop.table(table(sex,target),2)

## Number of Flouroscopic Vessels & Heart Disease
ftable(addmargins(table(ca,target)))
prop.table(table(ca,target),2)

## Severity of Heart Defect & Heart Disease
ftable(addmargins(table(thal,target)))
prop.table(table(thal,target),2)
```


```{r include = FALSE}
#Age distribution
hist(age)

#Heart Disease or not by Age
boxplot(age~target, main = "Heart Disease or Not by Age", xlab = "Heart Disease Present", ylab = "Age in Years")


#Sex breakdown
kable(table(sex))


#Chest pain breakdown
kable(table(cp))
```

 

```{r}
#Histogram of trestbps
hist(trestbps)

#Boxplot of trestbps by response
boxplot(trestbps~target, main = "Heart Disease or Not by trestbps", ylab = "Beats Per Second", xlab = "Heart Disease Present")

#Histogram of chol
hist(chol)

#Boxplot of chol vs response
boxplot(chol~target, main = "Heart Disease or Not by chol", xlab = "Heart Disease Present", ylab = "Cholestorol in mg/dl")

#Values of fbs in the data set
kable(table(fbs))

#Values of restecg in the data set
kable(table(restecg))

#Histogram of thalach
hist(thalach)

#Boxplot of thalach against response
boxplot(thalach~target)
#Some good differentiation here

#Values of exang in the data
kable(table(exang))

#Histogram of oldpeak
hist(oldpeak)
#Some strong right skew here that may need to be addressed if we use this as a continuous variable. And I think we should initially. 

#Boxplot of oldpeak
boxplot(oldpeak~target, main = "Heart Disease or Not vs oldpeak")

#Values of slope occuring
kable(table(slope))

#Values of ca occuring
kable(table(ca))

#Values of thal occuring
kable(table(thal))

#Distribution of the target response seems roughly 50-50
kable(table(target))

```